{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar Bibliotecas\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.tree import export_text\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split    \n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset MNIST\n",
    "digits = datasets.load_digits(n_class=10)\n",
    "\n",
    "images=digits.images\n",
    "targets=digits.target\n",
    "\n",
    "#Redimensionar matrix\n",
    "images=images.reshape(len(images),8*8)\n",
    "\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Criar nomes de características\n",
    "n_pixels = X.shape[1]\n",
    "feature_names = [f'pixel_{i}' for i in range(n_pixels)]\n",
    "\n",
    "# Dividir o dataset em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, targets, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DecisionTreeClassifier\n",
    "#Melhores parâmetros encontrados: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "#Precisão com os melhores parâmetros: 0.9763380758807589\n",
    "#Acurácia: 98.33%\n",
    "\n",
    "# Criar uma Decision Tree\n",
    "# Configuração do DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treinar a Decision Tree\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Prever as classes para o conjunto de teste\n",
    "y_pred_clf = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.10/site-packages/xgboost/core.py:158: UserWarning: [19:57:48] WARNING: /workspace/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "###XGBOOST\n",
    "#Parametros extraídos do Gridsearch\n",
    "#Melhores parâmetros encontrados: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 300, 'subsample': 0.8}\n",
    "#Precisão com os melhores parâmetros: 0.9672861014324429\n",
    "\n",
    "# Configurar o classificador XGBOOST\n",
    "xgb = XGBClassifier(\n",
    "    learning_rate=0.1,\n",
    "    max_depth=3,\n",
    "    n_estimators=100, \n",
    "    use_label_encoder=False, \n",
    "    eval_metric='mlogloss',\n",
    "    colsample_bytree = 0.8,\n",
    "    subsample= 0.8, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Treinar o modelo usando GridSearchCV\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "# Prever as classes para o conjunto de teste com o melhor modelo encontrado\n",
    "y_pred_xgb=xgb.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "###RANDOM FOREST\n",
    "#Parametros extraídos do Gridsearch\n",
    "#Melhores parâmetros encontrados: {'criterion': 'entropy', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
    "#Precisão com os melhores parâmetros: 0.9763380758807589\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300, \n",
    "    max_depth=None,\n",
    "    max_features= 'sqrt', \n",
    "    criterion='entropy', \n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split= 2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf=rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para avaliar múltiplos modelos e retornar o melhor desempenho\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Função para avaliar múltiplos modelos e retornar o melhor desempenho\n",
    "def evaluate_models(models_dict):\n",
    "    # Armazenar os resultados de todos os modelos\n",
    "    results_summary = []\n",
    "\n",
    "    for model_name, (model, y_test, y_pred) in models_dict.items():\n",
    "        # Avaliar o modelo\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        class_report = classification_report(y_test, y_pred)\n",
    "        \n",
    "        # Armazenar os resultados para comparação\n",
    "        results_summary.append({\n",
    "            'model_name': model_name,\n",
    "            'accuracy': accuracy,\n",
    "            'classification_report': class_report,\n",
    "            'conf_matrix': conf_matrix\n",
    "        })\n",
    "\n",
    "    # Ordenar os resultados por acurácia em ordem decrescente\n",
    "    results_summary.sort(key=lambda x: x['accuracy'], reverse=True)\n",
    "\n",
    "    # Criar um array formatado com os resultados\n",
    "    results_array = []\n",
    "    for i, result in enumerate(results_summary):\n",
    "        ranking = i + 1\n",
    "        model_name = result['model_name']\n",
    "        accuracy = result['accuracy'] * 100.0\n",
    "        results_array.append(f\"{ranking:<3} | {model_name:<25} | {accuracy:.1f}%\")\n",
    "\n",
    "    # Imprimir o array de resultados com cabeçalhos e bordas\n",
    "    print(\"#   | Modelo                    | Acurácia\")    \n",
    "    print(\"----+---------------------------+---------\") \n",
    "    for result in results_array:\n",
    "        print(result)\n",
    "        \n",
    "    # Imprimir e visualizar os resultados dos modelos restantes\n",
    "    for result in results_summary[3:]:\n",
    "        model_name = result['model_name']\n",
    "        print(f\"Resultados para {model_name}:\")\n",
    "        print(\"Accuracy: %.2f%%\" % (result['accuracy'] * 100.0))\n",
    "        print(\"Relatório de Classificação:\")\n",
    "        print(result['classification_report'])\n",
    "        \n",
    "        # Visualizar a Matriz de Confusão\n",
    "        plt.figure(figsize=(4, 3))\n",
    "        sns.heatmap(result['conf_matrix'], annot=True, fmt='d', cmap='Blues', \n",
    "                    xticklabels=list(range(10)), yticklabels=list(range(10)))\n",
    "        plt.title(f'Matriz de Confusão - {model_name}')\n",
    "        plt.xlabel('Predição')\n",
    "        plt.ylabel('Real')\n",
    "        plt.show()\n",
    "\n",
    "    return results_summary\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#   | Modelo                    | Acurácia\n",
      "----+---------------------------+---------\n",
      "1   | Random Forest             | 97.8%\n",
      "2   | XGBoost                   | 97.2%\n",
      "3   | Decision Tree Classifier  | 78.9%\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "#Avaliar Modelos\n",
    "#Posso avaliar os modelos com entropy ou gini\n",
    "################\n",
    "\n",
    "models_dict = {\n",
    "    \"Decision Tree Classifier\": (clf, y_test, y_pred_clf),\n",
    "    \"XGBoost\": (xgb, y_test, y_pred_xgb),\n",
    "    \"Random Forest\": (rf, y_test, y_pred_rf)\n",
    "}\n",
    "\n",
    "best_model_name, best_accuracy, results_summary = evaluate_models(models_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
